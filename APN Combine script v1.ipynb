{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f80563",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code is meant to combine multiple APN (Assessor Parcel Number) datasets into a single cohesive dataset for analysis and reporting purposes.\n",
    "It is meant for data analysts and GIS professionals who need to work with parcel data from various sources.\n",
    "It is a rough draft and may require further refinement and testing before use in a production environment.\n",
    "\n",
    "Thank you for your understanding and collaboration.\n",
    "\n",
    "-Andrew Sajor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for PDFs in: C:\\GIS\\APN_Data\\PDF_Input\n",
      "  > Processing: 147-076-15_Merger_9-6-24_SH.pdf\n",
      "    - FAILED to process 147-076-15_Merger_9-6-24_SH.pdf. Error: [Errno 13] Permission denied: 'C:\\\\GIS\\\\APN_Data\\\\CSV_Output\\\\147-076-15_Merger_9-6-24_SH_page_1.csv'\n",
      "  > Processing: 151-201-10_Combine_10-10-24_RMN.pdf\n",
      "    - Found table on page 1, saved to 151-201-10_Combine_10-10-24_RMN_page_1.csv\n",
      "  > Processing: Existing APN.pdf\n",
      "    - Found table on page 1, saved to Existing APN_page_1.csv\n",
      "\n",
      "PDF to CSV conversion complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "# This script scans a specified folder for PDF files, extracts tables from each PDF using pdfplumber, and saves them as CSV files in a designated output folder.\n",
    "# --- Configuration ---\n",
    "# Folder containing your PDF files to process!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "pdf_input_folder = r\"C:\\GIS\\APN_Data\\PDF_Input\"\n",
    "\n",
    "# Folder where the new CSV files will be saved !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "csv_output_folder = r\"C:\\GIS\\APN_Data\\CSV_Output\"\n",
    "\n",
    "# --- Main Script ---\n",
    "print(f\"Scanning for PDFs in: {pdf_input_folder}\")\n",
    "\n",
    "if not os.path.exists(csv_output_folder):\n",
    "    os.makedirs(csv_output_folder)\n",
    "    print(f\"Created output folder: {csv_output_folder}\")\n",
    "\n",
    "for filename in os.listdir(pdf_input_folder):\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_input_folder, filename)\n",
    "        print(f\"  > Processing: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                # Loop through all pages to find tables\n",
    "                for i, page in enumerate(pdf.pages):\n",
    "                    table = page.extract_table()\n",
    "                    if table:\n",
    "                        # Convert table data to a DataFrame\n",
    "                        df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                        \n",
    "                        # Create a new name for the output CSV\n",
    "                        csv_filename = f\"{os.path.splitext(filename)[0]}_page_{i+1}.csv\"\n",
    "                        output_path = os.path.join(csv_output_folder, csv_filename)\n",
    "                        \n",
    "                        # Save the DataFrame to a CSV file\n",
    "                        df.to_csv(output_path, index=False)\n",
    "                        print(f\"    - Found table on page {i+1}, saved to {csv_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    - FAILED to process {filename}. Error: {e}\")\n",
    "\n",
    "print(\"\\nPDF to CSV conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8609af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:43:07,906 - INFO - Script started.\n",
      "2025-08-14 13:43:07,908 - INFO - --- Step 2: Scanning folder and compiling CSV data ---\n",
      "2025-08-14 13:43:07,932 - INFO - \n",
      "Successfully compiled a master list of 7 total unique updates.\n",
      "2025-08-14 13:43:07,933 - INFO - \n",
      "--- Step 3: Updating ArcGIS Feature Layers ---\n",
      "2025-08-14 13:43:07,953 - INFO - --------------------------------------------------\n",
      "2025-08-14 13:43:07,954 - INFO - Processing Layer: BasicStocktonParcels\n",
      "2025-08-14 13:43:07,968 - INFO -   > Successfully accessed layer.\n",
      "2025-08-14 13:43:09,076 - INFO -   > Update complete. 7 features updated in 'BasicStocktonParcels'.\n",
      "2025-08-14 13:43:09,077 - INFO - --------------------------------------------------\n",
      "2025-08-14 13:43:09,077 - INFO - Processing Layer: Addresses\n",
      "2025-08-14 13:43:09,078 - INFO -   > Successfully accessed layer.\n",
      "2025-08-14 13:43:10,116 - INFO -   > Update complete. 9 features updated in 'Addresses'.\n",
      "2025-08-14 13:43:10,117 - INFO - \n",
      "Processing Complete.\n",
      "2025-08-14 13:43:10,118 - INFO - Script finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "import logging\n",
    "import time\n",
    "# This script updates APN fields in ArcGIS feature layers based on data compiled from CSV files.\n",
    "# --- 1. SETUP LOGGING ---\n",
    "# Create a unique log file name with a timestamp\n",
    "log_filename = f\"apn_update_log_{time.strftime('%Y%m%d-%H%M%S')}.log\"\n",
    "\n",
    "# Configure logging to output to both the console and a file\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename, mode='w'), # 'w' overwrites the file each time\n",
    "        logging.StreamHandler() # This will print to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "logging.info(\"Script started.\")\n",
    "\n",
    "# --- Configuration ---\n",
    "#You can change these paths and layer names as needed.!!!!!!!!!!!!!!!\n",
    "# Folder containing the CSV files with APN updates!!!!!!!!!!!!!!!!!!!\n",
    "csv_input_folder = r\"C:\\GIS\\APN_Data\\CSV_Input\"\n",
    "# Path to the ArcGIS Pro project file\n",
    "# Ensure this path points to your actual ArcGIS Pro project file!!!!!!!!!!!!!\n",
    "project_path = r\"C:\\GIS\\APN_Data\\YourProject.aprx\"\n",
    "# Name of the map within the ArcGIS Pro project!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Ensure this matches the name of the map in your project!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "map_name = \"Map\"\n",
    "# Layer names and field names for APN updates\n",
    "# Ensure these match the names in your ArcGIS Pro project!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "parcels_layer_name = \"Parcels\"\n",
    "parcels_apn_text_field = \"ApnText\"\n",
    "parcels_apn_numeric_field = \"apn\"\n",
    "# Layer names and field names for ADDRESSES\n",
    "# Ensure these match the names in your ArcGIS Pro project!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "addresses_layer_name = \"Addresses\"\n",
    "addresses_apn_text_field = \"ApnText\"\n",
    "addresses_apn_numeric_field = \"apn\"\n",
    "\n",
    "# --- Path and Folder Validation ---\n",
    "if not os.path.exists(csv_input_folder):\n",
    "    logging.critical(f\"FATAL ERROR: Input folder not found at: {csv_input_folder}\")\n",
    "    exit()\n",
    "\n",
    "if not os.path.exists(project_path):\n",
    "    logging.critical(f\"FATAL ERROR: ArcGIS Pro project not found at: {project_path}\")\n",
    "    exit()\n",
    "\n",
    "# --- Reusable function to update a layer's APN fields ---\n",
    "def update_layer_apns(map_obj, layer_name, text_field, numeric_field, update_dictionary):\n",
    "    logging.info(\"-\" * 50)\n",
    "    logging.info(f\"Processing Layer: {layer_name}\")\n",
    "    try:\n",
    "        lyr = map_obj.listLayers(layer_name)[0]\n",
    "        logging.info(f\"  > Successfully accessed layer.\")\n",
    "\n",
    "        # (Field validation code remains the same...)\n",
    "        \n",
    "        datasource_path = lyr.dataSource\n",
    "        workspace = os.path.dirname(datasource_path)\n",
    "        update_count = 0\n",
    "        with arcpy.da.Editor(workspace):\n",
    "            # Request the OID field to help with logging errors\n",
    "            with arcpy.da.UpdateCursor(lyr, [text_field, numeric_field, \"OID@\"]) as cursor:\n",
    "                for row in cursor:\n",
    "                    current_apn_text = row[0]\n",
    "                    if current_apn_text and current_apn_text in update_dictionary:\n",
    "                        new_apn_str = update_dictionary[current_apn_text]\n",
    "                        \n",
    "                        # --- FIX IS HERE ---\n",
    "                        try:\n",
    "                            # 1. Assign the string to the text field\n",
    "                            row[0] = new_apn_str\n",
    "                            \n",
    "                            # 2. Convert to integer and assign to the numeric field\n",
    "                            row[1] = int(new_apn_str) \n",
    "                            \n",
    "                            cursor.updateRow(row)\n",
    "                            update_count += 1\n",
    "                        except (ValueError, TypeError):\n",
    "                            # This will catch errors if new_apn_str is not a valid number\n",
    "                            logging.warning(f\"  > Could not update feature OID {row[2]}. APN '{new_apn_str}' is not a valid number.\")\n",
    "                        # --- END FIX ---\n",
    "                        \n",
    "        logging.info(f\"  > Update complete. {update_count} features updated in '{layer_name}'.\")\n",
    "        return update_count\n",
    "    except IndexError:\n",
    "        logging.error(f\"  > Layer named '{layer_name}' not found in the map.\")\n",
    "        return 0\n",
    "    except Exception:\n",
    "        logging.exception(f\"  > An unexpected error occurred while processing layer '{layer_name}':\")\n",
    "        return 0\n",
    "\n",
    "# --- 2. COMPILE DATA FROM CSV FILES ---\n",
    "logging.info(\"--- Step 2: Scanning folder and compiling CSV data ---\")\n",
    "all_dataframes = []\n",
    "for filename in os.listdir(csv_input_folder):\n",
    "    if filename.lower().endswith('.csv'):\n",
    "        full_path = os.path.join(csv_input_folder, filename)\n",
    "        try:\n",
    "            temp_df = pd.read_csv(full_path)\n",
    "            if temp_df.empty:\n",
    "                logging.warning(f\"  > Skipping empty file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            possible_old_cols = ['Existing APN (FROM)', 'Existing APN\\n(FROM)', 'Existing']\n",
    "            possible_new_cols = ['New APN (TO)', 'New APN']\n",
    "            \n",
    "            old_col_found = next((col for col in possible_old_cols if col in temp_df.columns), None)\n",
    "            new_col_found = next((col for col in possible_new_cols if col in temp_df.columns), None)\n",
    "\n",
    "            if old_col_found and new_col_found:\n",
    "                temp_df.rename(columns={old_col_found: 'Old_APN', new_col_found: 'New_APN'}, inplace=True)\n",
    "                if 'New_APN' in temp_df.columns:\n",
    "                    temp_df['New_APN'] = temp_df['New_APN'].ffill()\n",
    "                temp_df.dropna(subset=['Old_APN'], inplace=True)\n",
    "                \n",
    "                temp_df['Old_APN'] = temp_df['Old_APN'].astype(str).str.replace('-', '', regex=False).str.strip()\n",
    "                temp_df['New_APN'] = temp_df['New_APN'].astype(str).str.replace('-', '', regex=False).str.strip()\n",
    "                \n",
    "                final_df_chunk = temp_df[temp_df['Old_APN'].str.isnumeric() & temp_df['New_APN'].str.isnumeric()].copy()\n",
    "                all_dataframes.append(final_df_chunk[['Old_APN', 'New_APN']])\n",
    "            else:\n",
    "                logging.warning(f\"  > Skipping file '{filename}' due to missing required APN columns.\")\n",
    "\n",
    "        except Exception:\n",
    "            logging.exception(f\"  > Failed to process {filename}:\")\n",
    "\n",
    "if all_dataframes:\n",
    "    master_update_df = pd.concat(all_dataframes, ignore_index=True).drop_duplicates()\n",
    "    logging.info(f\"\\nSuccessfully compiled a master list of {len(master_update_df)} total unique updates.\")\n",
    "else:\n",
    "    master_update_df = None\n",
    "\n",
    "# --- 3. UPDATE ARCGIS FEATURE LAYERS ---\n",
    "if master_update_df is not None and not master_update_df.empty:\n",
    "    logging.info(\"\\n--- Step 3: Updating ArcGIS Feature Layers ---\")\n",
    "    try:\n",
    "        update_dict = pd.Series(master_update_df.New_APN.values, index=master_update_df.Old_APN).to_dict()\n",
    "        aprx = arcpy.mp.ArcGISProject(project_path)\n",
    "        m = aprx.listMaps(map_name)[0]\n",
    "        update_layer_apns(m, parcels_layer_name, parcels_apn_text_field, parcels_apn_numeric_field, update_dict)\n",
    "        update_layer_apns(m, addresses_layer_name, addresses_apn_text_field, addresses_apn_numeric_field, update_dict)\n",
    "        logging.info(\"\\nProcessing Complete.\")\n",
    "    except Exception:\n",
    "        logging.exception(\"A critical error occurred during the main ArcGIS update process:\")\n",
    "else:\n",
    "    logging.warning(\"\\nSkipping GIS update because no valid data was compiled.\")\n",
    "\n",
    "logging.info(\"Script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
